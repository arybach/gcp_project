sudo apt update
sudo apt upgrade -y
sudo apt install docker.io
sudo usermod -aG docker groot
sudo apt install docker-compose

# clean conda pyspark_env.tar.gz build to be passed on to pyspark-master and pyspark-workers
cd ~
mkdir opt
sudo chown groot:groot /opt
cd opt

# Update the package lists and install necessary packages
sudo apt-get update && \
    sudo apt-get install -y libgomp1 libavcodec-extra libavformat-dev libavutil-dev libswscale-dev && \
    sudo apt-get install -y openssl && \
    sudo apt-get install -y python3.9 python3-pip ffmpeg gfortran && \
    sudo apt-get install -y gcc g++ python3-dev git ninja-build && \
    sudo apt-get install -y wget bzip2 ca-certificates libglib2.0-0 libxext6 libsm6 libxrender1 && \
    sudo apt-get install -y libprotobuf-dev protobuf-compiler python3-protobuf python3-grpcio && \
    sudo rm -rf /var/lib/apt/lists/*

REBOOT -> stop/start instance, do not sudo reboot! 

# Install Miniconda
sudo rm -rf /opt/conda && \
    sudo wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh && \
    sudo /bin/bash ~/miniconda.sh -b -p /opt/conda && \
    sudo rm ~/miniconda.sh && \
    sudo chown -R $USER /opt/conda && \
    source /opt/conda/etc/profile.d/conda.sh && \
    conda activate base && \
    conda config --add channels conda-forge && \
    conda config --add channels anaconda && \
    conda update -y conda && \
    conda install -y conda-pack && \
    conda clean -afy

# Add Conda to the PATH
export PATH="/opt/conda/bin:${PATH}"

# Create and activate a new Conda environment
conda create -y --name pyspark_env && \
    conda activate pyspark_env

# Copy the requirements file into the Docker image
cp ~/gcp_project/requirements.txt /opt/requirements.txt

# Install dependencies to pyspark_env environment
conda config --add channels conda-forge && \
    conda config --add channels anaconda && \
    conda install -y opencv grpcio protobuf pyarrow pandas yt-dlp pipenv pyOpenSSL ffmpeg && \
    conda install --file /opt/requirements.txt && \
    conda clean -afy && \
    rm -rf /opt/conda/pkgs/*

# Pack the environment and copy to a destination machine
conda pack -f -n pyspark_env -o pyspark_env.tar.gz && \
    conda deactivate

# Copy the environment archive to the destination
mv pyspark_env.tar.gz /home/groot/gcp_project/
chmod +r /home/groot/gcp_project/pyspark_env.tar.gz